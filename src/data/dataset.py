import h5py
import json
import random
import numpy as np
from torch.utils.data import Dataset
from typing import Literal, List


class MixDataset(Dataset):
    """
    Provides access to the utterances of a simulated dataset (noisy, clean, and noise images for n_channels).

    Data:
    The underlying HDF5 file provides access to 
        1. The clean speech signal (low reverberation, but propagation delay to the microphones included)
        2. The noise signal (including reverberation)
        3. The clean speech image (including reverberation)
    The dataset provides 
        - noisy (clean image + noise)
        - noise
        - target (clean or clean image depending on dry_target variable)
    The SNR of the dataset itself if used if the snr_range is None and otherwise the signals are rescaled to match one of the specified SNR values.
    """
    def __init__(self,
                 stage: Literal['train', 'val', 'test'],
                 prep_files: dict,
                 n_channels: int,
                 meta_frame_length: int,
                 dry_target: bool,
                 disable_random: bool,
                 snr_range: List[int] = None,
                 target_dir = 0,
                 noise_snr: List[int] = None
                 ):
        """
        Initialize the dataset.

        :param stage: the dataset stage ('train', 'val', 'test)
        :param prep_files: a dictionary specifying the HDF5 data file and meta data file generated by the preprocessing.py files. Keys are 'data', 'meta', 'train_data', 'train_meta', 'val_data', 'val_meta', 'test_data' and 'test_meta'. The 'data' and 'meta' keys serve as default if other keys are not specified.
        :param n_channels: the number of microphone channels
        :param meta_frame_length: the metaframe length (e.g. randomly cut 1 second of data -> 16000 samples per metaframe
        :param dry_target: use the dry signal as target (as opposed to the reverberant)
        :param has_dry: if set to False the given clean 
        :param disable_random: turn off random metaframe selection in every epoch (only makes sense for validation or training debugging)
        :param target_dir: angle of the target direction
        :param noise_snr: a list of SNRs for additive white noise (no noise if None)
        """
        self.stage = stage

        self.data_prep_path = prep_files.get('data', None)
        self.meta_prep_path = prep_files.get('meta', None)

        stage_data_path = prep_files.get(f'{stage}_data', None)
        stage_meta_path = prep_files.get(f'{stage}_meta', None)

        if stage_data_path:
            self.data_prep_path = stage_data_path
        if stage_meta_path: 
            self.meta_prep_path = stage_meta_path
        if self.data_prep_path is None:
            raise ValueError(f'Specified prep paths are not valid: {prep_files}')
        if self.meta_prep_path is None:
            raise ValueError(f'Specified prep paths are not valid: {prep_files}')

        self.n_channels = n_channels

        self.meta_frame_length = meta_frame_length

        self.use_dry_target = dry_target

        self.snr_range = snr_range
        self.noise_snr = noise_snr

        self.target_dir = target_dir

        with h5py.File(self.data_prep_path, 'r') as prep_file:
            self.n_samples = prep_file[stage].shape[0]
        with open(self.meta_prep_path, 'r') as meta_file:
            self.meta_data = json.load(meta_file)[stage]

        self.disable_random = disable_random
        self.start_idxs = None
        if disable_random:
            self._init_seg_start_idxs()

    def _open_hdf5(self):
        self.prep_file = h5py.File(self.data_prep_path, 'r')
        # self.audio_data = self.prep_file[self.stage]

    def _init_seg_start_idxs(self):
        """
        Initializes the random cut for every utterance. Can be used to disable random segment selection during
        validation which can help to visualize improvements.
        """
        start_idxs = {}
        for i in range(self.n_samples):
            data = self.__getitem__(i)
            start_idxs[i] = data['start_idx']
        self.start_idxs = start_idxs

    def __len__(self):
        return self.n_samples

    def __getitem__(self, idx, start_idx: int = -1):
        """
        Get sample for given index starting and random position not specified otherwise.

        :param idx: the sample index
        :param start_idx: the start index for some random cut (random if -1 is given)
        :return: clean, noise, and noisy arrays [CHANNEL, SAMPLES], snr and start index
        """

        if self.disable_random and not self.start_idxs is None:
            start_idx = self.start_idxs[idx]
        reverb_clean_audio, dry_clean_audio, noise_audio, start_idx = self._read_audio_segment(idx, start_idx)
        
        if not self.snr_range is None and not len(self.snr_range) == 0:
            snr = random.choice(self.snr_range)
            noise_scale = snr_scale_factor(reverb_clean_audio, noise_audio, snr)
        else:
            noise_scale = 1

        mix_td = reverb_clean_audio + noise_scale * noise_audio
        
        if not self.noise_snr is None:
            snr = random.choice(self.noise_snr)
            noise = np.random.randn(*reverb_clean_audio.shape)
            noise_scale = snr_scale_factor(mix_td, noise, snr)
            mix_td += noise_scale * noise

        target_dir = self.meta_data[str(idx)].get('target_dir', self.target_dir)

        return {'noisy_td': mix_td,
                'clean_td': dry_clean_audio if self.use_dry_target else reverb_clean_audio,
                'reverb_clean_td': reverb_clean_audio,
                'noise_td': noise_audio,
                'start_idx': start_idx, 
                'sample_idx': idx,
                'target_dir': target_dir}

    def get_utterance(self, idx):
        """
        Get the full stored utterance from the datast.

        :param idx: the sample idex
        :return: noisy, clean and noise utterance and sample name
        """
        sample_name = self.meta_data[str(idx)].get('name', f'sample_{idx}')
        n_samples = self.meta_data[str(idx)]['n_samples']

        reverb_clean_audio, dry_clean_audio, noise_audio = self._read_audio(idx)

        target_dir = self.meta_data[str(idx)].get('target_dir', self.target_dir)

        return (reverb_clean_audio + noise_audio)[:, :n_samples], \
               (dry_clean_audio if self.use_dry_target else reverb_clean_audio)[:, :n_samples], \
               noise_audio[:, :n_samples], \
               sample_name, \
               target_dir

    def _read_audio_segment(self, idx, start_idx):
        """
        Get clean and noise signal segments for given index starting at random position if not specified otherwise.

        :param idx: the sample index
        :param start_idx: the start index for some random cut (random if -1 is given)
        :return: clean and noise arrays [CHANNEL, SAMPLES] and start index
        """
        if not hasattr(self, 'prep_file'):
            self._open_hdf5()

        audio = self.prep_file[self.stage][idx]
        n_samples = min(self.meta_data[str(idx)]['n_samples'], audio.shape[-1])

        if self.meta_frame_length < 0:
            return audio[..., :n_samples], 0  # return full audio if meta_frame_length is -1

        possible_start = n_samples - self.meta_frame_length

        if possible_start < 0:  # example shorter than selected meta_frame length
            return np.concatenate((audio[0, :self.n_channels, :n_samples],
                                    np.zeros((self.n_channels, self.meta_frame_length - n_samples), dtype=np.float32)),
                                   axis=-1), \
                   np.concatenate((audio[2, :self.n_channels, :n_samples],
                                    np.zeros((self.n_channels, self.meta_frame_length - n_samples), dtype=np.float32)),
                                   axis=-1), \
                   np.concatenate((audio[1, :self.n_channels, :n_samples],
                                   np.zeros((self.n_channels, self.meta_frame_length - n_samples), dtype=np.float32)),
                                  axis=-1), \
                   0
        elif start_idx >= 0:  # use given start index
            return audio[0, :self.n_channels, start_idx:start_idx + self.meta_frame_length], \
                   audio[2, :self.n_channels, start_idx:start_idx + self.meta_frame_length], \
                   audio[1, :self.n_channels, start_idx:start_idx + self.meta_frame_length], \
                   start_idx
        else:  # cut random metaframe from utterance
            start = random.randint(0, possible_start)
            end = start + self.meta_frame_length
            return audio[0, :self.n_channels, start: end], \
                   audio[2, :self.n_channels, start: end], \
                   audio[1, :self.n_channels, start: end], \
                   start

    def _read_audio(self, idx):
        """
        Get full clean and noise utterance for the given index.

        :param idx: the sample index
        :return: clean and noise arrays [CHANNEL, SAMPLES]
        """
        if not hasattr(self, 'prep_file'):
            self._open_hdf5()

        audio = self.prep_file[self.stage][idx]

        return audio[0], audio[2], audio[1]


def snr_scale_factor(speech: np.ndarray, noise: np.ndarray, snr: int):
    """
    Compute the scale factor that has to be applied to a noise signal in order for the noisy (sum of noise and clean)
    to have the specified SNR.

    :param speech: the clean speech signal [..., SAMPLES]
    :param noise: the noise signal [..., SAMPLES]
    :param snr: the SNR of the mixture
    :return: the scaling factor
    """

    noise_var = np.mean(np.var(noise, axis=-1))
    speech_var = np.mean(np.var(speech, axis=-1))

    factor = np.sqrt(speech_var / np.maximum((noise_var * 10. ** (snr / 10.)), 10**(-6)))

    return factor

def target_level_scale_factor(audio: np.ndarray, target_level: int, eps: float = 1e-6):
    """
    Compute the scale factor that has to be applied to the signal to normalize to the specified target level.

    :param audio: the time domain signal [..., SAMPLES]
    :param target_level: the target level in db
    :return: the scaling factor
    """
    rms = np.mean(np.square(np.abs(audio)))
    scale = np.sqrt((10 ** (target_level / 10)) / rms) / np.abs(audio).max()
    return scale
